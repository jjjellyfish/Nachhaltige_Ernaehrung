---
title: "Score Nachhaltige Ernährung"
author: "IGES Institut"
format: html
editor: visual
toc: true
---

```{r setup}
#| message: false
#| warning: false
library(tidyverse)
library(janitor)
library(broom)
library(haven) #Einlesen von .sav oder .dta
library(xlsx)
library(knitr)
library(kableExtra)

library(lavaan)

options(knitr.kable.NA = '')
```

# 0. Prep

```{r data}
# Datensatz mit Meta-Infos zu den Items
items <- read.xlsx('./data/Items.xlsx', sheetIndex = 1)


# Daten aus AOK-Familienstudie
overall_dat <- read_dta('./data/AOK_Datensatz.dta')
#names(overall_dat)

dat <- overall_dat %>% select(lfdn, v_309:v_318, 
                              contains('Ernährungskompetenz'), 
                              v_319:v_371)
```

```{r functions}
rsquared_aov <- function(var, dat) {
  # berechne R² aus Anovas, Variablen müssen numerisch sein
  model <- paste('{var} ~ ', kov_string)
  aov_result <-  aov(eval(parse(text = model)), data=dat)
  tidy_aov <- tidy(aov_result)
  sum_squares_regression <- sum(tidy_aov$sumsq[1:(length(tidy_aov$sumsq)-1)])
  sum_squares_residuals <- tidy_aov$sumsq[length(tidy_aov$sumsq)]
  rsquared <- sum_squares_regression /(sum_squares_regression + sum_squares_residuals)
  return(rsquared)
}

pR2_mcfadden <- function(var, dat) {
  # berechne Pseudo-R² nach McFadden aus ordinaler Regression, Variablen müssen Faktoren sein
  model <- paste('{var} ~ ', kov_string)
  ord_null <-  MASS::polr(co_m1 ~ 1, data=dat, Hess=TRUE)
  ord_result <-  MASS::polr(eval(parse(text = model)), data=dat, Hess=TRUE)
  pR2_mcfadden <-  1 - ord_result$deviance / ord_null$deviance
  return(pR2_mcfadden)
}

pR2_nagelkerke <- function(var, dat) {
  # berechne Pseudo-R² nach Nagelkerke aus ordinaler Regression, Variablen müssen Faktoren sein
  model <- paste('{var} ~ ', kov_string)
  ord_result <-  rms::lrm(eval(parse(text = model)), data=dat)
  pR2_nagelkerke <- as.numeric(ord_result$stats["R2"])
  return(pR2_nagelkerke)
}
```


Vorgehen:

-   zunächst werden Punkte gemäß der jeweiligen Skala vergeben
-   im nächsten Schritt werden Items auf eine gemeinsame Skala zwischen 0 & 1 transformiert (siehe hierfür https://www.ibm.com/support/pages/transforming-different-likert-scales-common-scale)
-   der Nachhaltigkeitsscore wird für jede Person von 0 bis 100 ausgegeben

```{r sust}
# Itemauswahl
items_auswahl <- items %>% filter(eignung_score %in% c('ja', 'vielleicht')) %>% na.omit()
sust <- dat %>% select(lfdn, any_of(items_auswahl$item_nr))
```

# 1. Vorbereitung der Items

## 1.1 Kodierung einzelner Bereiche

Punkte für die jeweiligen Antworten vergeben --\> Sortierung nach Bereichen (ersteinmal so wie sie in der Auswahl vom 28.10. festegelgt wurden)

### 1.1.1 Einstellung / Bedeutung

```{r}
#| label: kodierung_einstellung
# Diagnostik von haven_labelled-Objekten
# check <- labelled::look_for(tmp)

### Frage 7.2: Welche Aspekte sind Ihnen am Essen am wichtigsten?
sust$v_325[sust$v_325 == 6] <- NA
sust <- sust %>% select(-v_322, -v_323, -v_324, -v_326)

table(sust$v_325)

### Frage 7.9: Welche Hindernisse für klimafreundliche Ernährung? (invertiert)
sust <- sust %>% 
  mutate(v_352_357 = rowSums(select(., v_352:v_357)),
         v_352_357 = ifelse(v_352_357==0 & v_358==0, NA, v_352_357)) %>% 
  select(-(v_352:v_358))

### restliche Items ohne Veränderungen
ids <- c('v_359', 'v_364', 'v_365')

sust <- sust %>% 
  mutate_all(as.numeric) %>%
  mutate(across(any_of(ids), ~na_if(.,0)))
```

### 1.1.2 Wissen /Fertigkeiten

```{r}
#| label: kodierung_wissen

### Frage 7.4: klimaschädlichstes Lebensmittel (Wissensfrage)
#labelled::look_for(sust)
sust <- sust %>% mutate(
  v_333 = case_when(
    v_333 == 1 ~ 3, 
    v_333 %in% c(2,3,5) ~ 2, 
    v_333 == 4 ~ 1, 
    v_333 == 0 ~ as.double(NA)
  )
)

### restliche Items ohne Verädnerungen
ids <- c('v_321', 'v_327', 'v_328', 'v_330', 'v_331', 'v_332', 'v_360')

sust <- sust %>% 
  mutate(across(any_of(ids), ~na_if(.,0)))
```

### 1.1.3 Verhalten

```{r}
#| label: kodierung_verhalten

### Frage 7.7: Wie ernähren Sie sich und ihr Kind?
tmp <- sust %>% select(v_336:v_345) %>% 
  mutate_all(as.factor) 

sust <- sust %>% mutate(
  ern_erw = case_when(
    v_336 == 1 ~ 1,
    v_338 == 1 ~ 2,
    v_340 == 1 ~ 3,
    v_342 == 1 ~ 4,
    v_344 == 1 ~ 5,
  ), 
    ern_kid = case_when(
    v_337 == 1 ~ 1,
    v_339 == 1 ~ 2,
    v_341 == 1 ~ 3,
    v_343 == 1 ~ 4,
    v_345 == 1 ~ 5,
  ),
) %>% 
  select(-(v_336:v_345))


### restliche Items ohne Veränderungen
ids <- c('v_329', 'v_334', 'v_335', 'v_346', 'v_347', 'v_348', 'v_349', 'v_350', 'v_351', 'v_366')

sust <- sust %>% 
  mutate(across(any_of(ids), ~na_if(.,0)))
```


**Item-Datensatz vervollständigen**
```{r}
#| label: add_item_descriptions
#names(items)
items <- items %>% 
  add_row(item_nr='v_352_357', item='Wie viele Hindernisse für eine klima-/umweltfreundliche Ernährung werden genannt?', bereich='Hindernisse', bereich_neu='Einstellung / Bedeutung') %>% 
  add_row(item_nr='ern_erw', item='Wie ernähren Sie sich?', bereich='Verhalten', bereich_neu='Verhalten') %>%
  add_row(item_nr='ern_kid', item='Wie ernähren Sie Ihr Kind?', bereich='Verhalten', bereich_neu='Verhalten')
```

```{r}
#| label: overview_items
sust_items <- names(sust)[2:length(sust)]

items %>%
  filter(item_nr %in% sust_items) %>%
  select(item_nr, bereich_neu, item) %>% 
  arrange(match(bereich_neu, c('Einstellung / Bedeutung', 'Wissen / Fertigkeiten'))) %>%
  kbl() %>%
  kable_styling( position = "left") %>% 
  column_spec(c(1,2), border_left = F, border_right = T) %>% 
  row_spec(c(0,5,13), extra_css = "border-bottom: 1px solid", hline_after=TRUE) 
```


## 1.2 Transformation & Invertierung

**Transformation** <br> Da die Items auf Antwortskalen mit unterschiedlich vielen Ausprägungen zu beantworten sind, müssen diese vor einer Zusammenführung zunächst auf eine einheitliche Skala transformiert werden. Dabei soll die minimale Ausprägung 0 und die maximale Ausprägung 1 sein.

```{r}
#| label: transformation
transform_scale <- function(x) {
  (x - min(x, na.rm = TRUE)) /  (max(x, na.rm=TRUE) - min(x, na.rm = TRUE))
}

sust <- sust %>% 
  mutate_all(as.numeric) %>% 
  mutate(across(v_321:ern_kid, transform_scale))

### check
check <- dlookr::diagnose(sust)
check <- dlookr::diagnose_numeric(sust)
```

**Invertierung** <br> Die Items sollen so kodiert sein, dass ein hoher numerischer Wert (Max 1) mit maximal nachhaltiger Ernährung einhergeht. Ein niedriger Wert (Min 0) bedeutet umgekehrt eine wenig nachhaltige Ernährung.

Alle Items, die in die umgekehrte Richtung kodiert sind, werden umgedreht.

```{r}
#| label: invert
ids <- c('v_325','v_352_357')

sust <- sust %>%
  mutate(across(any_of(ids), ~ 1-.))
```

```{r diag}
check <- dlookr::diagnose(sust) 
check <- dlookr::diagnose_numeric(sust) %>% select(variables, min, max, everything())
```



# 2. Messmodell

Quelle: Coltman et al. (2007): Formative versus reflcetive measurement models <https://doi.org/10.1016/j.jbusres.2008.01.013>

Bei reflektiven latenten Konstrukten wird angenommen, dass die Variation in einem Indikator X auf die Variation in dem latenten Konstrukt Y zurückgeht. Wenn eine Intervention das latente Konstrukt Y verändert, kann es durch Messung von Indikator X erkannt werden (Kausalitätsrichtung: Konstrukt Y verändert Indikator X). Reflektive Konstrukte erfordern Skalen mit positiv korrelierten Items. Für einen Großteil der psychologischen Skalen werden reflektive latente Konstrukte angenommen, eine Ausnahme sind häufig klinische Störungsbilder.

Bei formativen latenten Konstrukten **formen** verschiedene Indikatoren ein latentes Konstrukt Y. Es gibt keine Annahme bezüglich der Korrelationsstruktur dieser Indikatoren. Die Kausalitätsrichtung ist umgekehrt: eine Veränderung auf den Indikatoren bewirkt eine Veränderung im Konstrukt Y.

#### Theoretische Prüfung des Konstrukts Nachhaltige Ernährung

1.  Die Art des Konstrukts: <br>

    Reflektive latente Konstrukte existieren in einem absoluten Sinne und unabhängig von den Indikatoren, z.B. Einstellungen und Persönlichkeit. Ein formatives latentes Konstrukt existiert nur als Kombination seiner Indikatoren, z.B. der Human Development Index (HDI). <br>

    Nachhaltige Ernährung existiert tendenziell nicht als eigene Entität. Die Nachhaltigkeit der Ernährung setzt sich aus verschiedenen Aspekten zusammen (z.B. wenig bis kein Fleischkonsum, saisonale und regionale Ernährung, wenig Verpackungsmüll etc.).

2.  Richtung der Kausalität <br>

    **reflektiv**: Variation in the construct causes variation in the item measures, variation in item measures does not cause variation in the construct\
    **formativ**: variation in the construct does not cause variation in the item measures, variation in item measures causes variation in the construct

    Verscheide Aspekte der klima- und umweltbewussten Ernährung formen gemeinsam eine nachhaltige Ernährung.

3.  Charakteristika der Indikatoren

    Bei reflektiven Konstrukten beinhalten alle Indikatoren ein gemeinsames Motiv (Korrelation der Items), die Indikatoren sind austauschbar und das Hinzufügen oder Entfernen einzelne Indikatoren verändert das Konstrukt nicht konzeptuell.

    Bei formativen Konstrukten teilen die Indikatoren kein gemeinsames Motiv (sie müssen daher nicht korrelieren), die Indikatoren sind nicht austauschbar und das Weglassen von Indikatoren kann das Konstrukt konzeptuell verändern.

    Die verschiedenen Aspekte nachhaltiger Ernährung können, müssen aber nicht notwendigerweise zusammenhängen (z.B. Fleischkonsum & saisonale Ernährung)

**Bei nachhaltiger Ernährung handelt es sich vermutlich um ein formatives Konstrukt.**

#### Empirische Implikationen

-   keine Annahme der Korrelationsstruktur von Indikatoren (keine, niedrige und hohe Korrelationen möglich) --\> Diagnostik von Passung in eingeschränktem Maße möglich

-   da Methoden zur Reliabilitätsprüfung auf der Annahme von interner Konsistenz (Korrelation von Indikatoren) fußen, ist keine einfache universell akzeptierte Prüfung der Reliabilität möglich

-   keine Möglichkeit der Bewertung von Messfehlern

-   Prüfung von Kollinearität besonders wichtig, da Einfluss von Gewichtung bestimmter inhaltlicher Aspekte im Konstrukt



## 2.1 CFA: Prüfung auf drei Bereiche
```{r}
tmp <- sust %>% na.omit()

#| label: cfa
### Messmodell aufsetzen
model <- '
  f1_einstellung =~ v_325 + v_352_357 + v_359 + v_364 + v_365
  f2_wissen =~ v_321 + v_327 + v_328 + v_330 + v_331 + v_332 + v_333 + v_360
  f3_verhalten =~ v_329 + v_334 + v_335 + ern_erw + ern_kid + v_346 + v_347 + v_348 + v_349 + v_350 + v_351 + v_366
  '

### CFA
fit <- lavaan::cfa(model=model, data=tmp, std.lv=TRUE, fixed.x=FALSE)
#summary(fit)
tmp <- as.data.frame(fitMeasures(fit, c("rmsea", "cfi", "srmr")))

tmp %>%  
  tibble::rownames_to_column(., 'Index') %>%
  kbl(booktabs = T,  digits = 4, centering=F, row.names=FALSE, 
      col.names=c('Index', 'Wert'), 
      caption = 'Fitindizes der angenommenen dreifaktoriellen Struktur des FLQ')
```
--> **das Modell passt nicht auf die Daten**



## 2.2 EFA: Extraktion von Faktoren
```{r}
#|label: cor_matrix
tmp <- sust %>% na.omit()
datamatrix <- cor(tmp[,c(-1)])

corrplot::corrplot(datamatrix, method="color", order='hclust', 
                   tl.col = "black", tl.cex = 0.7)

corrplot::corrplot(datamatrix, method="number", order='hclust', 
                   number.cex = 0.7,   tl.col = "black", tl.cex = 0.7)
```


**Exploratorische Faktorenanalyse** <br>

Interpretationshilfe: <https://m-clark.github.io/posts/2020-04-10-psych-explained/>
```{r}
#|label: efa_nfactors
fafitfree <- psych::fa(tmp, nfactors = ncol(tmp), rotate = "none")

n_factors <- length(fafitfree$e.values)
scree <- data.frame(
  Factor_n =  as.factor(1:n_factors), 
  Eigenvalue = fafitfree$e.values)

ggplot(scree, aes(x = Factor_n, y = Eigenvalue, group = 1)) + 
  geom_point() + geom_line() +
  xlab("Number of factors") +
  ylab("Initial eigenvalue") +
  labs( title = "Scree Plot", 
        subtitle = "(Based on the unreduced correlation matrix)")

parallel <- psych::fa.parallel(tmp)
```

```{r}
#| label: efa

efa <- psych::fa(r=tmp[,c(-1)], nfactors=6,
 max.iter=100,
 rotate='promax')

print(efa)
```


```{r}
#| label: loadings_df
#| warning: false
#| echo: false

### loadings_df
efa_df <- bind_cols(rownames(efa$loadings), efa$loadings, efa$communality, efa$uniquenesses)
names(efa_df)[1] <- c('item')
names(efa_df)[(length(efa_df)-1):length(efa_df)] <- c('h2', 'u2')

# remove low loadings
efa_df <- efa_df %>%
  mutate(across(2:(ncol(.)-2), ~ifelse(abs(.) <= 0.2, NA, .)))

write.xlsx(efa_df, file='data/EFA_loadings.xlsx')
```

```{r}
#|label: alpha
alpha <- psych::alpha(select(tmp, contains('v_')), check.keys = F)
alpha$total$std.alpha
```



## 2.3 EFA: Extraktion von Faktoren nach erneuter Itemselektion

```{r}
#|label: cor_matrix2
tmp <- sust %>% 
  select( -v_327, -v_328, -v_333, -v_352_357, -v_366) %>% 
  na.omit()

datamatrix <- cor(tmp[,c(-1)])

corrplot::corrplot(datamatrix, method="color", order='hclust', 
                   tl.col = "black", tl.cex = 0.7)

corrplot::corrplot(datamatrix, method="number", order='hclust', 
                   number.cex = 0.7,   tl.col = "black", tl.cex = 0.7)
```


**Exploratorische Faktorenanalyse** <br>

Interpretationshilfe: <https://m-clark.github.io/posts/2020-04-10-psych-explained/>
```{r}
#|label: efa_nfactors2
fafitfree <- psych::fa(tmp, nfactors = ncol(tmp), rotate = "none")

n_factors <- length(fafitfree$e.values)
scree <- data.frame(
  Factor_n =  as.factor(1:n_factors), 
  Eigenvalue = fafitfree$e.values)

ggplot(scree, aes(x = Factor_n, y = Eigenvalue, group = 1)) + 
  geom_point() + geom_line() +
  xlab("Number of factors") +
  ylab("Initial eigenvalue") +
  labs( title = "Scree Plot", 
        subtitle = "(Based on the unreduced correlation matrix)")

parallel <- psych::fa.parallel(tmp)
```

```{r}
#| label: efa2
efa <- psych::fa(r=tmp[,c(-1)], nfactors=5,
 max.iter=100,
 rotate='promax')

print(efa)
```


```{r}
#| label: loadings_df2
#| warning: false
#| echo: false

### loadings_df
efa_df <- bind_cols(rownames(efa$loadings), efa$loadings, efa$communality, efa$uniquenesses)
names(efa_df)[1] <- c('item')
names(efa_df)[(length(efa_df)-1):length(efa_df)] <- c('h2', 'u2')

# remove low loadings
efa_df <- efa_df %>%
  mutate(across(2:(ncol(.)-2), ~ifelse(abs(.) <= 0.2, NA, .)))

write.xlsx(efa_df, file='data/EFA_loadings2.xlsx')
```

```{r}
#| label: alpha2
alpha <- psych::alpha(select(tmp, contains('v_')), check.keys = F)
alpha$total$std.alpha
```





# 3. Score bilden
```{r}
#| label: score
items_v1 <- c('v_321', 'v_325', 'v_329', 'v_330', 'v_331', 'v_332', 'v_334', 'v_335', 'v_346', 'v_347', 'v_348', 'v_349', 'v_350', 'v_351', 'v_359', 'v_360', 'v_364', 'v_365', 'ern_erw', 'ern_kid')

# nur für vollständig ausgefüllte Items
v1 <- sust %>% 
  na.omit() %>%
  select(lfdn, any_of(items_v1)) %>% 
  mutate(
    sum_valid = rowSums(!is.na(select(., 2:length(.)))),
    score_v1 = rowSums(select(., 2:length(.)), na.rm=TRUE)/ sum_valid)

mosaic::favstats(v1$score_v1)
```

```{r}
#| label: verteilung
ggplot(v1, aes(x=score_v1)) +
  geom_histogram(binwidth=0.005, fill="#69b3a2", color="#e9ecef", alpha=0.9) +
  ggtitle("Verteilung der Scores - Version 1") +
  theme_bw() +
  theme(plot.title = element_text(size=15))
```


# 4. Cutoff bestimmen

## 4.1 Vorbereitung

### 4.1.1 Fehlden Items
```{r}
#| label: fehlende_items 
v1 <- sust %>% 
  select(lfdn, any_of(items_v1)) %>% 
  mutate(
    sum_valid = rowSums(!is.na(select(., 2:length(.)))),
    score_v1=rowSums(select(., 2:length(.)), na.rm=TRUE)/ sum_valid)

# Anzahl valider Angaben
tabyl(v1$sum_valid, show_na = TRUE) %>%  
  mutate(percent=percent*100) %>%
  kbl(booktabs = T,  digits = 4, centering=F, row.names=FALSE, 
      col.names=c('valide Items', 'n', '%'), 
      caption = 'Fitindizes der angenommenen dreifaktoriellen Struktur des FLQ')%>% 
  kable_styling(full_width = T)

# Mittelwerte in Abhängigkeit der Anzahl valider Werte
v1 <- v1 %>% mutate(valid_group=case_when(
  sum_valid < 10 ~ '<10',
  between(sum_valid, 10, 17) ~ '10-17',
  sum_valid>17 ~ '>17'
))

psych::describeBy(v1$score_v1, group=v1$valid_group, mat=TRUE)

```
Da die Items zum Teil sehr unterschiedliche Aspekte der nachhaltigen Ernährung abbilden, wird für die Berechnung eines Nachhaltigkeits-Scores ein hoher Anteil an valide beantwortet Items von 90% (18 von 20 Items) vorausgesetzt. 
Für die Berechnung von Cutoffs werden alle Personen ausgeschlossen, die weniger als 18 Items beantwortet haben (n = `r length(v1$sum_valid[v1$sum_valid<=17])`, `r round(length(v1$sum_valid[v1$sum_valid<=17]) / length(v1$sum_valid),4) * 100`%). Die Brechnung eines Nachhaltigkeits-Scores sowie die folgenden Modelle zur Cut-Off-Wert-Berechnung berücksichtigen ausschließlich Personen mit mindestens 18 beantworteten Nachhaltigkets-Items (n = `r length(v1$sum_valid[v1$sum_valid>17])` von N=`r length(v1$sum_valid)`, `r round(length(v1$sum_valid[v1$sum_valid>17]) / length(v1$sum_valid),4) * 100`%).


```{r}
#| label: fehlende_items2
v1 <- v1 %>% filter(sum_valid>17) # weiter nur ohne diese Fälle (min. 18 valide Items)
```


### 4.1.2 Cutoff-Modelle festlegen
Die Festlegung der Cut-Offs erfolgt zunächst explorativ. Zur Bestimmung distinkter Gruppen Nachhaltigen Ernährung entlang des kontinuierlichen Nachhaltigkeits-Scores kamen sowohl verteilungs- als auch score-basierte Ansätze zur Anwendung. Verteilungsbasierte Ansätze berücksichtigen die Verteilung des Nachhaltigkeits-Scores in der Stichprobe. Score-basierte Ansätze sind verteilungsunabhängig und basieren auf der im Nachhaltigkeits-Fragebogen erreichbaren Punktzahl.
```{r}
#| label: cutoff_modelle
### Verteilungsbasiert
## 1. Quintile
v1$co_int1 <- ggplot2::cut_number(v1$score_v1, 5)
v1$co_m1 <- cut(v1$score_v1 , breaks = quantile(v1$score_v1, c(0, .2, .4, .6, .8, 1)), labels=1:5, include.lowest=TRUE)

## 2. Quartile
v1$co_int2 <- ggplot2::cut_number(v1$score_v1, 4)
v1$co_m2 <- cut(v1$score_v1 , breaks = quantile(v1$score_v1, c(0, .25, .5, .75, 1)), labels=1:4, include.lowest=TRUE)

## 3. Terzile
v1$co_int3 <- ggplot2::cut_number(v1$score_v1, 3)
v1$co_m3 <- cut(v1$score_v1 , breaks = quantile(v1$score_v1, c(0, 1/3, 2/3, 1)), labels=1:3, include.lowest=TRUE)

## 4. Quintile mit kleinen Randgruppen
v1$co_int4 <- cut(v1$score_v1 , breaks = quantile(v1$score_v1, c(0, .125, .375, .625, .875, 1)), include.lowest=TRUE)
v1$co_m4 <- cut(v1$score_v1 , breaks = quantile(v1$score_v1, c(0, .125, .375, .625, .875, 1)), labels=1:5, include.lowest=TRUE)

## 5. Qauartile mit kleinen Randgruppen
v1$co_int5 <- cut(v1$score_v1 , breaks = quantile(v1$score_v1, c(0, .125, .5, .875, 1)), include.lowest=TRUE)
v1$co_m5 <- cut(v1$score_v1 , breaks = quantile(v1$score_v1, c(0, .125, .5, .875, 1)), labels=1:4, include.lowest=TRUE)


### Score-basiert
## 6. Quintile max. Score
v1 <- v1 %>% mutate(co_m6=case_when(
  score_v1 <= 0.2 ~ 1,
  score_v1 <= 0.4 ~ 2,
  score_v1 <= 0.6 ~ 3,
  score_v1 <= 0.8 ~ 4,
  score_v1 <= 1.0 ~ 5))

## 7. Quartile max. Score
v1 <- v1 %>% mutate(co_m7=case_when(
  score_v1 <= 0.25 ~ 1,
  score_v1 <= 0.5 ~ 2,
  score_v1 <= 0.75 ~ 3,
  score_v1 <= 1.0 ~ 4))

## 8. Terzile max. Score
v1 <- v1 %>% mutate(co_m8=case_when(
  score_v1 <= 1/3 ~ 1,
  score_v1 <= 2/3 ~ 2,
  score_v1 <= 1.0 ~ 3))

## 9. Quartile/Terzile max. Score
v1 <- v1 %>% mutate(co_m9=case_when(
  score_v1 <= 1/3 ~ 1,
  score_v1 <= 0.5 ~ 2,
  score_v1 <= 2/3 ~ 3,
  score_v1 <= 1.0 ~ 4))
```


```{r}
#| label: uebersicht_cutoff_werte
models <- c('Nullmodell', '1. Quintile', '2. Quartile', '3. Terzile', '4. Quintile mit kleinen Randgruppen', '5. Quartile mit kleinen Randgruppen', '6. Quintile max. Score', '7. Quartile max. Score', '8. Terzile max. Score', '9. Quartile/Terzile max. Score')
```

**Kovariaten**: Geschlecht der erwachsenen Person, Alter und Geschlecht des Zielkindes, Anzahl Kinder unter 14 Jahren, soziökonomischer Status der Familie, Migrationsgeschichte, German Index of Socioeconomic Deprivation (GISD), Anzahl HBSC multiple psychosomatische Beschwerden, Gesundheitsstatus des Elternteils, Gesundheitsstatus des Kindes
<br><br>


UCLA-Guide für ordinale Modelle: <https://stats.oarc.ucla.edu/r/dae/ordinal-logistic-regression/>
```{r}
#| label: cutoff_lineare_modelle
#Kovariaten vorbereiten
kovariaten <- c('v_4', 'Alter_Zielkind_2', 'Geschlecht_Zielkind', 'Kinder_unter_14', 'SES_max', 'Migrationsgeschichte', 'GISD_Score', 'Anzahl_HBSC', 'Gesundheitsstatus_Elternteil', 'Gesundheitsstatus_Kind', 'Score_Ernährungskompetenz') #
kov_string <- toString(paste(kovariaten, collapse = ' + '))

# Datensatz mit Kovariaten vorbereiten
kovs <- overall_dat %>% select(lfdn, any_of(kovariaten))
v2 <- left_join(v1, kovs, by='lfdn')


### R² aus linearen Modelle
v2 <- v2 %>% mutate_at(vars(contains('co_m')), as.numeric)
tmp <- select(v2, score_v1, contains('co_m'))

R2_linear <- vector("double", length(tmp))
for (i in seq_along(tmp)) {            
  R2_linear[[i]] <- rsquared_aov(tmp[[i]], v2)
}


### R² aus ordinalen Modellen
v2 <- v2 %>% mutate_at(vars(contains('co_m')), as.factor)
tmp <- select(v2, contains('co_m'))

pR2_mcfad <- vector("double", length(tmp))
for (i in seq_along(tmp)) {            
  pR2_mcfad[[i]] <- pR2_mcfadden(tmp[[i]], v2)
}

pR2_nagel <- vector("double", length(tmp))
for (i in seq_along(tmp)) {            
  pR2_nagel[[i]] <- pR2_nagelkerke(tmp[[i]], v2)
}
```





